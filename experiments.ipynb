{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 6\n",
    "\n",
    "## Running the experiments\n",
    "\n",
    "In the previous stage, our team selected `Sammon's error` function and `Genetic algorithm` and `Simulated annealing` for the experiments, so we wil use them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df = pd.read_csv('combined-metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Name', axis=1).values\n",
    "y = df['Name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 35)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.42625369e+00, 3.77802360e+01, 2.97935103e+01, ...,\n",
       "        1.81400000e+03, 1.58500000e+04, 0.00000000e+00],\n",
       "       [2.02732240e+00, 9.52868852e+00, 6.37568306e+00, ...,\n",
       "        9.22000000e+02, 2.64500000e+03, 0.00000000e+00],\n",
       "       [1.67987805e+00, 1.17048780e+01, 8.17073171e+00, ...,\n",
       "        2.79100000e+03, 1.14790000e+04, 0.00000000e+00],\n",
       "       ...,\n",
       "       [4.29198473e+00, 2.41488550e+01, 1.87232824e+01, ...,\n",
       "        3.82000000e+02, 6.43600000e+03, 0.00000000e+00],\n",
       "       [9.15789474e+00, 3.77017544e+01, 2.96842105e+01, ...,\n",
       "        1.78000000e+02, 1.38800000e+03, 0.00000000e+00],\n",
       "       [2.24528302e+00, 1.04371069e+01, 7.09119497e+00, ...,\n",
       "        8.01000000e+02, 2.98200000e+03, 0.00000000e+00]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ART', 'BentoML', 'Bokeh', 'Camel', 'CatBoost', 'Causal ML',\n",
       "       'Chainer', 'Computer Vision', 'D2L', 'Darts', 'Dash', 'DeepChem',\n",
       "       'DeepMind Control', 'DeepPavlov', 'Detectron2', 'DIGITS',\n",
       "       'DragGan', 'EasyOCR', 'ELI5', 'EvalAI', 'facenet', 'FaceSwap',\n",
       "       'Fairseq', 'FastAI', 'FeatureTools', 'FiftyOne', 'gensim',\n",
       "       'Giskard', 'Gluonts', 'Google Flax', 'Google JAX', 'GPT-Engineer',\n",
       "       'GPTDiscord', 'Gradio', 'Gymnasium', 'Horovod', 'ImageAI',\n",
       "       'imbalanced-learn', 'InsightFace', 'Kaolin', 'Kedro', 'Keras',\n",
       "       'Kserve', 'Lightning', 'Ludwig', 'Mage-ai', 'Mars', 'Matplotlib',\n",
       "       'metatransformer', 'Mindsdb', 'MLflow', 'Mycroft',\n",
       "       'Neural Prophet', 'NNI', 'Numpy', 'ONNX', 'Open-Assistant',\n",
       "       'OpenAI Baselines', 'OpenAI Python API library', 'OpenVINO',\n",
       "       'Optuna', 'Paddle', 'Pandas', 'Pocker', 'Pybrain', 'PyCaret',\n",
       "       'pycm', 'PyMC', 'Pyro', 'PyTensor', 'PyTorch',\n",
       "       'Pytorch image models', 'qlib', 'Rasa', 'Ray', 'Recommenders',\n",
       "       'Redash', 'river', 'RLAgents', 'scikit-learn', 'Scikit-multiflow',\n",
       "       'SciPy', 'Scrapy', 'seaborn', 'Snorkel', 'Sonnet', 'spaCy',\n",
       "       'Stable Diffusion webui', 'Stanza', 'Statsmodels', 'SuperAGI',\n",
       "       'TensorFlow', 'TensorForce', 'TensorLayer', 'TensorLayerX',\n",
       "       'torchvision', 'TPOT', 'Transformers', 'TTS', 'vit-pytorch',\n",
       "       'Yellowbrick'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 35)\n",
      "(21, 35)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Determining the minimal subset of metrics on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sammon's error function that we will use as an objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sammon's error function\n",
    "def sammons_error(X, Y):\n",
    "    \"\"\"\n",
    "    X: Original high-dimensional data\n",
    "    Y: Low-dimensional representation\n",
    "    \"\"\"\n",
    "    # Calculate pairwise distances in X and Y\n",
    "    dist_orig = np.sqrt(np.sum((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2, axis=-1))\n",
    "    dist_lowd = np.sqrt(np.sum((Y[:, np.newaxis, :] - Y[np.newaxis, :, :]) ** 2, axis=-1))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    epsilon = 1e-12\n",
    "\n",
    "    numerator = np.sum(((dist_orig - dist_lowd) * 2) / (dist_orig + epsilon))\n",
    "    denominator = np.sum(dist_orig)\n",
    "\n",
    "    error = numerator / denominator\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_genetic(individual, X):\n",
    "    # Create a subset of features based on the individual\n",
    "    subset_X = X[:, np.array(individual).astype(bool)]\n",
    "\n",
    "    # Calculate the fitness using the `sammons_error` function\n",
    "    fitness = -sammons_error(X, subset_X)\n",
    "    return fitness,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects giperion\\lsd-metrics\\venv\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "d:\\Projects giperion\\lsd-metrics\\venv\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "from deap import creator, base, tools, algorithms\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set up the genetic algorithm\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "\n",
    "# Functions to limit the number of features in the individual to 10\n",
    "def create_individual():\n",
    "    individual = [random.randint(0, 1) for _ in range(X.shape[1])]\n",
    "    while sum(individual) > 10:\n",
    "        indices = np.random.choice(np.arange(X.shape[1]), size=sum(individual) - 10, replace=False)\n",
    "        for idx in indices:\n",
    "            individual[idx] = 0\n",
    "    return creator.Individual(individual)\n",
    "\n",
    "\n",
    "def mate(ind1, ind2):\n",
    "    child1, child2 = [toolbox.clone(ind) for ind in (ind1, ind2)]\n",
    "    tools.cxTwoPoint(child1, child2)\n",
    "\n",
    "    # Limit the number of features in the child to 10\n",
    "    while sum(child1) > 10:\n",
    "        indices = np.random.choice(np.arange(X.shape[1]), size=sum(child1) - 10, replace=False)\n",
    "        for idx in indices:\n",
    "            child1[idx] = 0\n",
    "    while sum(child2) > 10:\n",
    "        indices = np.random.choice(np.arange(X.shape[1]), size=sum(child2) - 10, replace=False)\n",
    "        for idx in indices:\n",
    "            child2[idx] = 0\n",
    "    return child1, child2\n",
    "\n",
    "\n",
    "def mutate(individual):\n",
    "    child = toolbox.clone(individual)\n",
    "    tools.mutFlipBit(child, indpb=0.05)\n",
    "    while sum(child) > 10:\n",
    "        indices = np.random.choice(np.arange(X.shape[1]), size=sum(child) - 10, replace=False)\n",
    "        for idx in indices:\n",
    "            child[idx] = 0\n",
    "    return child,\n",
    "\n",
    "\n",
    "toolbox.register(\"individual\", create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", fitness_genetic, X=X_train)\n",
    "toolbox.register(\"mate\", mate)\n",
    "toolbox.register(\"mutate\", mutate)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg         \tstd        \tmin         \tmax         \n",
      "0  \t100   \t-4.31971e-06\t1.99471e-06\t-7.11684e-06\t-6.47558e-07\n",
      "1  \t67    \t-2.53719e-06\t1.7305e-06 \t-6.44468e-06\t-5.76285e-07\n",
      "2  \t62    \t-1.43723e-06\t1.17744e-06\t-7.14823e-06\t-5.75688e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  \t59    \t-8.88344e-07\t2.45486e-07\t-1.6428e-06 \t-1.42149e-07\n",
      "4  \t49    \t-6.81458e-07\t1.98324e-07\t-1.12059e-06\t-1.41985e-07\n",
      "5  \t63    \t-8.03043e-07\t8.90059e-07\t-4.47984e-06\t-1.41493e-07\n",
      "6  \t67    \t-6.50613e-07\t8.31126e-07\t-5.57951e-06\t-1.18825e-07\n",
      "7  \t62    \t-5.13197e-07\t7.99811e-07\t-4.34602e-06\t-4.73123e-08\n",
      "8  \t63    \t-3.02316e-07\t5.47433e-07\t-4.10646e-06\t-4.73123e-08\n",
      "9  \t57    \t-3.14486e-07\t7.02476e-07\t-4.33258e-06\t-4.73123e-08\n",
      "10 \t60    \t-2.41189e-07\t5.07083e-07\t-3.96707e-06\t-4.73123e-08\n",
      "11 \t62    \t-3.53432e-07\t8.67722e-07\t-4.34514e-06\t-2.80246e-08\n",
      "12 \t59    \t-1.2649e-07 \t3.32131e-07\t-3.19841e-06\t-1.33527e-08\n",
      "13 \t70    \t-1.62408e-07\t5.48405e-07\t-3.3177e-06 \t-1.33527e-08\n",
      "14 \t58    \t-1.28638e-07\t5.25719e-07\t-3.92922e-06\t-1.28161e-08\n",
      "15 \t55    \t-2.92484e-07\t8.53752e-07\t-4.08706e-06\t-1.28161e-08\n",
      "16 \t63    \t-1.601e-07  \t6.09567e-07\t-3.89812e-06\t-1.22859e-08\n",
      "17 \t64    \t-2.27e-07   \t7.51497e-07\t-3.34765e-06\t-1.22859e-08\n",
      "18 \t63    \t-1.429e-07  \t5.46898e-07\t-3.27538e-06\t-1.22859e-08\n",
      "19 \t67    \t-1.84473e-07\t6.53278e-07\t-3.72732e-06\t-1.22859e-08\n",
      "20 \t67    \t-2.3742e-07 \t7.01427e-07\t-3.29477e-06\t-1.22859e-08\n",
      "21 \t48    \t-1.13859e-07\t4.54136e-07\t-3.19752e-06\t-1.22859e-08\n",
      "22 \t60    \t-8.00714e-08\t3.27496e-07\t-3.14258e-06\t-1.22859e-08\n",
      "23 \t60    \t-1.04134e-07\t4.48861e-07\t-3.19646e-06\t-1.22859e-08\n",
      "24 \t62    \t-6.40936e-08\t3.32206e-07\t-3.26613e-06\t-1.22859e-08\n",
      "25 \t56    \t-9.17984e-08\t3.47988e-07\t-3.22858e-06\t-1.22859e-08\n",
      "26 \t55    \t-6.95035e-08\t3.30315e-07\t-3.19752e-06\t-1.22859e-08\n",
      "27 \t47    \t-1.84165e-07\t6.99455e-07\t-4.08674e-06\t-1.22859e-08\n",
      "28 \t58    \t-1.27239e-07\t4.57994e-07\t-3.14428e-06\t-1.22859e-08\n",
      "29 \t53    \t-3.43141e-08\t8.26769e-08\t-4.37839e-07\t-1.22859e-08\n",
      "30 \t63    \t-1.15371e-07\t4.97931e-07\t-3.74257e-06\t-1.22859e-08\n",
      "31 \t57    \t-1.27493e-07\t4.63492e-07\t-3.14486e-06\t-1.22859e-08\n",
      "32 \t72    \t-8.83079e-08\t4.3923e-07 \t-3.14332e-06\t-1.22859e-08\n",
      "33 \t60    \t-1.97665e-07\t6.76567e-07\t-3.72753e-06\t-1.22859e-08\n",
      "34 \t66    \t-7.03018e-08\t3.23815e-07\t-3.14332e-06\t-1.22859e-08\n",
      "35 \t55    \t-1.08513e-07\t5.06515e-07\t-3.92727e-06\t-1.22859e-08\n",
      "36 \t56    \t-2.33256e-07\t7.72439e-07\t-4.08438e-06\t-1.22859e-08\n",
      "37 \t66    \t-1.42698e-07\t5.46328e-07\t-3.19753e-06\t-1.22859e-08\n",
      "38 \t68    \t-1.89622e-07\t6.50807e-07\t-3.608e-06  \t-1.22859e-08\n",
      "39 \t68    \t-2.81802e-07\t8.66384e-07\t-5.29881e-06\t-1.22859e-08\n",
      "40 \t61    \t-1.08867e-07\t4.53086e-07\t-3.22871e-06\t-1.22859e-08\n",
      "41 \t67    \t-1.06003e-07\t3.63327e-07\t-3.32832e-06\t-3.27877e-09\n",
      "42 \t47    \t-6.16218e-08\t3.27364e-07\t-3.22872e-06\t-3.27877e-09\n",
      "43 \t64    \t-1.75607e-07\t6.72365e-07\t-4.08549e-06\t-3.27877e-09\n",
      "44 \t57    \t-1.28884e-07\t5.47187e-07\t-3.22873e-06\t-3.27877e-09\n",
      "45 \t61    \t-7.38577e-08\t3.26015e-07\t-3.1243e-06 \t-3.27877e-09\n",
      "46 \t54    \t-1.54394e-07\t5.50321e-07\t-3.14332e-06\t-3.27877e-09\n",
      "47 \t63    \t-4.53772e-08\t1.37555e-07\t-8.37598e-07\t-3.27877e-09\n",
      "48 \t53    \t-1.3575e-07 \t6.30071e-07\t-3.98005e-06\t-3.27877e-09\n",
      "49 \t56    \t-6.71317e-08\t3.28757e-07\t-3.14428e-06\t-3.27877e-09\n",
      "50 \t57    \t-1.65028e-07\t6.92664e-07\t-5.30967e-06\t-3.27877e-09\n",
      "51 \t62    \t-6.55547e-08\t3.49483e-07\t-3.34392e-06\t-3.27877e-09\n",
      "52 \t56    \t-1.28844e-07\t4.71436e-07\t-3.24259e-06\t-3.27877e-09\n",
      "53 \t50    \t-1.70237e-07\t6.59068e-07\t-3.59078e-06\t-3.27877e-09\n",
      "54 \t57    \t-2.23254e-07\t7.53171e-07\t-3.25105e-06\t-3.27877e-09\n",
      "55 \t49    \t-1.85284e-07\t6.67815e-07\t-4.0337e-06 \t-3.27877e-09\n",
      "56 \t61    \t-6.78051e-08\t3.68156e-07\t-3.59066e-06\t-3.27877e-09\n",
      "57 \t66    \t-1.70196e-07\t6.69106e-07\t-4.0903e-06 \t-3.27877e-09\n",
      "58 \t54    \t-7.02386e-08\t4.0421e-07 \t-3.98099e-06\t-3.27877e-09\n",
      "59 \t59    \t-5.60267e-08\t3.20694e-07\t-3.12597e-06\t-3.27877e-09\n",
      "60 \t57    \t-2.55948e-07\t8.63404e-07\t-4.05527e-06\t-3.27877e-09\n",
      "61 \t64    \t-1.46429e-07\t5.806e-07  \t-3.69885e-06\t-3.27877e-09\n",
      "62 \t62    \t-1.48437e-07\t5.57497e-07\t-3.25181e-06\t-3.27877e-09\n",
      "63 \t62    \t-2.63745e-07\t8.81592e-07\t-4.61114e-06\t-3.27877e-09\n",
      "64 \t54    \t-6.47692e-08\t3.25142e-07\t-3.12597e-06\t-3.27877e-09\n",
      "65 \t60    \t-1.98197e-07\t7.05248e-07\t-3.27198e-06\t-3.27877e-09\n",
      "66 \t55    \t-1.449e-07  \t6.02209e-07\t-4.01104e-06\t-3.27877e-09\n",
      "67 \t70    \t-1.37904e-07\t5.50587e-07\t-3.15017e-06\t-3.27877e-09\n",
      "68 \t54    \t-1.34986e-07\t5.402e-07  \t-3.14469e-06\t-3.27877e-09\n",
      "69 \t51    \t-9.03285e-08\t4.12159e-07\t-3.98099e-06\t-3.27877e-09\n",
      "70 \t50    \t-1.42366e-07\t6.11486e-07\t-4.19516e-06\t-3.27877e-09\n",
      "71 \t65    \t-9.69009e-08\t4.48092e-07\t-3.15051e-06\t-3.27877e-09\n",
      "72 \t63    \t-1.1853e-07 \t5.84105e-07\t-3.87557e-06\t-3.27877e-09\n",
      "73 \t64    \t-6.99828e-08\t3.30622e-07\t-3.12596e-06\t-3.27877e-09\n",
      "74 \t59    \t-1.54765e-07\t5.56214e-07\t-3.2106e-06 \t-3.27877e-09\n",
      "75 \t56    \t-8.7335e-08 \t4.4436e-07 \t-3.145e-06  \t-3.27877e-09\n",
      "76 \t63    \t-2.02554e-07\t6.84909e-07\t-3.12597e-06\t-3.27877e-09\n",
      "77 \t48    \t-1.34992e-07\t5.19377e-07\t-3.97872e-06\t-3.27877e-09\n",
      "78 \t59    \t-8.6955e-08 \t4.52563e-07\t-3.25072e-06\t-3.27877e-09\n",
      "79 \t71    \t-1.23822e-07\t5.04371e-07\t-3.8754e-06 \t-3.27877e-09\n",
      "80 \t63    \t-9.74197e-08\t4.51025e-07\t-3.17977e-06\t-3.27877e-09\n",
      "81 \t53    \t-3.00468e-08\t1.12035e-07\t-8.27187e-07\t-3.27877e-09\n",
      "82 \t59    \t-7.27013e-08\t3.45546e-07\t-3.15051e-06\t-3.27877e-09\n",
      "83 \t53    \t-9.50898e-08\t4.52776e-07\t-3.24277e-06\t-3.27877e-09\n",
      "84 \t57    \t-9.69383e-08\t4.58562e-07\t-3.2523e-06 \t-3.27877e-09\n",
      "85 \t67    \t-1.30026e-07\t5.46279e-07\t-3.12596e-06\t-3.27877e-09\n",
      "86 \t55    \t-8.36074e-08\t3.48424e-07\t-3.12523e-06\t-3.27877e-09\n",
      "87 \t59    \t-1.36829e-07\t5.52614e-07\t-3.2523e-06 \t-3.27877e-09\n",
      "88 \t63    \t-1.28525e-07\t5.65705e-07\t-3.59081e-06\t-3.27877e-09\n",
      "89 \t66    \t-1.82685e-07\t6.73758e-07\t-4.05545e-06\t-3.27877e-09\n",
      "90 \t66    \t-2.45374e-07\t8.31336e-07\t-4.08766e-06\t-3.27877e-09\n",
      "91 \t60    \t-6.7988e-08 \t3.27386e-07\t-3.12597e-06\t-3.27877e-09\n",
      "92 \t49    \t-1.04674e-07\t5.77858e-07\t-4.57566e-06\t-3.27877e-09\n",
      "93 \t71    \t-1.3235e-07 \t5.41745e-07\t-3.17992e-06\t-3.27877e-09\n",
      "94 \t45    \t-1.33609e-07\t5.53254e-07\t-3.34392e-06\t-3.27877e-09\n",
      "95 \t63    \t-5.14578e-08\t1.43468e-07\t-8.65385e-07\t-3.27877e-09\n",
      "96 \t61    \t-6.80823e-08\t3.4958e-07 \t-3.36463e-06\t-3.27877e-09\n",
      "97 \t52    \t-3.85743e-08\t1.11413e-07\t-4.97877e-07\t-3.27877e-09\n",
      "98 \t49    \t-9.1851e-08 \t4.4993e-07 \t-3.21077e-06\t-3.27877e-09\n",
      "99 \t69    \t-1.94535e-07\t7.5134e-07 \t-5.31198e-06\t-3.27877e-09\n",
      "100\t66    \t-5.24396e-08\t3.33508e-07\t-3.27135e-06\t-3.27877e-09\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Run the genetic algorithm\n",
    "population = toolbox.population(n=100)\n",
    "hof = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "population, log = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=100, stats=stats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subset of metrics: ['effort', 'CEE', 'LLDC', 'TLLOC', 'TNM', 'TNOS', 'TCLOC', 'WarningCritical', 'WarningMajor', 'WarningMinor']\n",
      "Best fitness: (-3.2787695694992544e-09,)\n",
      "Length of best subset: 10\n"
     ]
    }
   ],
   "source": [
    "# Get the best individual (subset of metrics)\n",
    "best_individual = hof.items[0]\n",
    "best_subset_genetic = [df.columns[i+1] for i, bit in enumerate(best_individual) if bit]\n",
    "\n",
    "print(\"Best subset of metrics:\", best_subset_genetic)\n",
    "print(\"Best fitness:\", fitness_genetic(best_individual, X_train))\n",
    "print(\"Length of best subset:\", len(best_subset_genetic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepting worse state with probability: 0.998559124585052\n",
      "Accepting worse state with probability: 0.9999856554000673\n",
      "Accepting worse state with probability: 0.9955725283756776\n",
      "Accepting worse state with probability: 0.9982212176324723\n",
      "Accepting worse state with probability: 0.6404976324095744\n",
      "Accepting worse state with probability: 1.0\n",
      "Accepting worse state with probability: 0.9969576433847761\n",
      "Accepting worse state with probability: 0.9909566525721489\n",
      "Accepting worse state with probability: 0.5819519985342155\n",
      "Accepting worse state with probability: 0.9999935506320803\n",
      "Accepting worse state with probability: 0.892947663942996\n",
      "Accepting worse state with probability: 0.9999999394955846\n",
      "Accepting worse state with probability: 1.0\n",
      "Accepting worse state with probability: 0.9960664660226065\n",
      "Accepting worse state with probability: 0.890981964796782\n",
      "Accepting worse state with probability: 0.8403951452912932\n",
      "Accepting worse state with probability: 0.9209622706479704\n",
      "Accepting worse state with probability: 0.9872515910032379\n",
      "Accepting worse state with probability: 0.9975864294218573\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def fitness_annealing(X, subset_X):\n",
    "    return -sammons_error(X, subset_X)\n",
    "    \n",
    "def generate_random_subset(X, best_subset):\n",
    "    # Generate a random subset of features based on the best subset\n",
    "    subset = np.array(best_subset, dtype=int) if best_subset is not None else np.zeros(X.shape[1], dtype=int)\n",
    "\n",
    "    # Randomly select features to add or remove\n",
    "    for i in range(X.shape[1]):\n",
    "        if random.random() < 0.1:\n",
    "            subset[i] = 1 - subset[i]\n",
    "\n",
    "    return subset\n",
    "\n",
    "def annealing(X):\n",
    "    # Simulated annealing parameters\n",
    "    t = 1e-9 # Initial temperature\n",
    "    t_min = 1e-100 # Minimum temperature\n",
    "    cooling_factor = 0.9999 # Temperature damping factor\n",
    "    max_iterations = 10000 # Maximum number of iterations\n",
    "    best_subset = generate_random_subset(X, None)\n",
    "    best_score = fitness_annealing(X, X[:,best_subset==1])\n",
    "    tried_subsets = set()\n",
    "    \n",
    "    i = 0\n",
    "    while i < max_iterations:\n",
    "        # Generate a new random subset\n",
    "        subset = generate_random_subset(X, best_subset)\n",
    "\n",
    "        # Limit the number of features in the subset to 10\n",
    "        if sum(subset) > 10:\n",
    "            continue\n",
    "\n",
    "        # Skip if subset already tried\n",
    "        subset_hash = hash(str(subset))\n",
    "\n",
    "        if subset_hash in tried_subsets:\n",
    "            continue\n",
    "\n",
    "        tried_subsets.add(subset_hash)\n",
    "\n",
    "        score = fitness_annealing(X, X[:,subset==1]) # Evaluate subset\n",
    "\n",
    "        if score > best_score:\n",
    "            # Accept new better state unconditionally\n",
    "            best_subset = subset\n",
    "            best_score = score\n",
    "\n",
    "        elif random.random() < math.exp((score - best_score) / t):\n",
    "            # Accept new worse state with probability\n",
    "            print(\"Accepting worse state with probability:\", math.exp((score - best_score) / t))\n",
    "            best_subset = subset\n",
    "            best_score = score\n",
    "\n",
    "        # Cool temperature\n",
    "        t = t * cooling_factor\n",
    "\n",
    "        # Check if cooled enough\n",
    "        if t < t_min:\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return best_subset, best_score\n",
    "\n",
    "best_subset, best_score = annealing(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subset: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0]\n",
      "Best sammon's error result: 3.2787695694992544e-09\n",
      "3.2787695694992544e-09\n"
     ]
    }
   ],
   "source": [
    "print(\"Best subset:\", best_subset)\n",
    "print(\"Best sammon's error result:\", -best_score)\n",
    "print(sammons_error(X_train, X_train[:, best_subset==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['effort', 'CEE', 'LLDC', 'TLLOC', 'TNM', 'TNOS', 'TCLOC', 'WarningCritical', 'WarningMajor', 'WarningMinor']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "best_subset_annealing = [df.columns[i+1] for i, bit in enumerate(best_subset) if bit]\n",
    "print(best_subset_annealing)\n",
    "print(len(best_subset_annealing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm result:  ['effort', 'CEE', 'LLDC', 'TLLOC', 'TNM', 'TNOS', 'TCLOC', 'WarningCritical', 'WarningMajor', 'WarningMinor']\n",
      "Simulated annealing result: ['effort', 'CEE', 'LLDC', 'TLLOC', 'TNM', 'TNOS', 'TCLOC', 'WarningCritical', 'WarningMajor', 'WarningMinor']\n",
      "Genetic training score: 3.2787695694992544e-09\n",
      "Annealing training score: 3.2787695694992544e-09\n",
      "Genetic validation score: 1.3740122716132385e-08\n",
      "Annealing validation score: 1.3740122716132385e-08\n"
     ]
    }
   ],
   "source": [
    "print(\"Genetic algorithm result: \", best_subset_genetic)\n",
    "print(\"Simulated annealing result:\", best_subset_annealing)\n",
    "\n",
    "X_genetic = X_train[:, np.array(best_individual).astype(bool)]\n",
    "X_annealing = X_train[:, np.array(best_subset).astype(bool)]\n",
    "\n",
    "X_genetic_test = X_test[:, np.array(best_individual).astype(bool)]\n",
    "X_annealing_test = X_test[:, np.array(best_subset).astype(bool)]\n",
    "\n",
    "print(\"Genetic training score:\", sammons_error(X_train, X_genetic))\n",
    "print(\"Annealing training score:\", sammons_error(X_train, X_annealing))\n",
    "\n",
    "print(\"Genetic validation score:\", sammons_error(X_test, X_genetic_test))\n",
    "print(\"Annealing validation score:\", sammons_error(X_test, X_annealing_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
